api:
  class: NeuralNetwork
  method: BatchTrain
  signature: void NeuralNetwork::BatchTrain(const int & batch, float learningRate)
documentation:
  brief: Trains the neural network using batch gradient descent with the specified
    learning rate.
  description: The BatchTrain method performs a single iteration of training on a
    neural network using batch gradient descent. It processes the entire dataset in
    one go, computing gradients across all samples and updating the network weights
    accordingly. This method is typically used in machine learning applications within
    TrinityCore for training AI behaviors or decision-making systems. The training
    process requires pre-loaded training data and assumes that the network has been
    properly initialized with appropriate architecture and weights. This method modifies
    the internal state of the neural network by adjusting its weights and biases based
    on the computed gradients.
  parameters:
  - name: batch
    description: The size of the batch to use for training. This determines how many
      samples are processed together in each training iteration. Must be a positive
      integer representing the number of training examples per batch.
  - name: learningRate
    description: The learning rate controls the step size during weight updates. Higher
      values may lead to faster convergence but can cause instability, while lower
      values provide more stable but slower training. Must be a positive floating-point
      value typically between 0.001 and 1.0.
  returns: null
  examples:
  - title: Basic Neural Network Training
    code: 'NeuralNetwork network;

      // Initialize network with appropriate architecture

      network.Initialize(4, 3, 2); // Input layer: 4, Hidden layer: 3, Output layer:
      2

      network.BatchTrain(32, 0.01f); // Train with batch size of 32 and learning rate
      of 0.01'
    language: cpp
  - title: Advanced Training with Multiple Iterations
    code: "NeuralNetwork network;\n// Initialize and load training data\nnetwork.Initialize(10,\
      \ 5, 1);\nfor (int epoch = 0; epoch < 1000; ++epoch)\n{\n    network.BatchTrain(64,\
      \ 0.001f);\n    if (epoch % 100 == 0)\n        std::cout << \"Epoch: \" << epoch\
      \ << \"\\n\";\n}"
    language: cpp
  notes: This method assumes that training data has already been loaded into the neural
    network. The batch size should be chosen based on available memory and computational
    resources. For optimal performance, consider using smaller batches with higher
    learning rates for faster convergence, or larger batches with lower learning rates
    for more stable updates.
  warnings: Calling this method without properly initializing the neural network or
    loading training data may result in undefined behavior or crashes. Extremely high
    learning rates can cause the training process to diverge, while very low learning
    rates may result in extremely slow convergence or getting stuck in local minima.
  related:
  - NeuralNetwork::Initialize
  - NeuralNetwork::ForwardPass
  - NeuralNetwork::BackwardPass
  - NeuralNetwork::SetTrainingData
metadata:
  confidence: 0.85
  generated_at: '2025-11-06T07:58:36.883140'
  generator: lmstudio-qwen3-coder-30b
  version: 1.0.0
  source: core
