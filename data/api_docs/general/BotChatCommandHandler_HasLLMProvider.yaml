api:
  class: BotChatCommandHandler
  method: HasLLMProvider
  signature: bool BotChatCommandHandler::HasLLMProvider()
documentation:
  brief: Checks whether the bot chat command handler has an LLM provider configured.
  description: The HasLLMProvider method determines if a language model (LLM) provider
    has been initialized and is available for use within the bot chat command handler.
    This functionality is essential for bots that rely on AI-driven responses or natural
    language processing capabilities. The method typically checks internal state flags
    or references to ensure that an LLM backend is properly set up before attempting
    to process commands that require AI assistance. It's commonly used as a precondition
    check before invoking methods that depend on LLM functionality.
  parameters: []
  returns: Returns true if an LLM provider is configured and ready for use; otherwise,
    returns false.
  examples:
  - title: Basic Usage Check
    code: "if (botChatCommandHandler.HasLLMProvider()) {\n    // Proceed with AI-enabled\
      \ command processing\n    botChatCommandHandler.ProcessAICommand(\"hello\");\n\
      } else {\n    // Fallback to standard command handling\n    botChatCommandHandler.ProcessStandardCommand(\"\
      hello\");\n}"
    language: cpp
  notes: This method likely performs a lightweight check on internal state rather
    than attempting to connect to an external service. It's designed to be fast and
    safe to call frequently during command processing loops.
  warnings: null
  related:
  - SetLLMProvider
  - GetLLMProvider
  - IsAIEnabled
metadata:
  confidence: 0.85
  generated_at: '2025-11-01T17:24:25.578099'
  generator: lmstudio-qwen3-coder-30b
  version: 1.0.0
  source: core
