api:
  class: QFunction
  method: SelectAction
  signature: uint32_t QFunction::SelectAction(const int & state, float epsilon)
documentation:
  brief: Selects an action based on the current state and exploration rate for Q-learning
    AI behavior.
  description: The SelectAction method implements a Q-learning decision-making process
    within the TrinityCore AI framework. It takes the current state of the AI agent
    and an epsilon value representing the exploration rate, then returns the index
    of the selected action. This method is typically used in reinforcement learning
    scenarios where the AI must balance between exploiting known good actions and
    exploring new possibilities. The epsilon parameter controls the probability of
    choosing a random action (exploration) versus the best known action (exploitation).
    When epsilon is high, the agent explores more; when low, it exploits its knowledge.
  parameters:
  - name: state
    description: The current state identifier used to determine which action to select
      from the Q-table. This value should correspond to a valid state index in the
      AI's internal state space.
  - name: epsilon
    description: Exploration rate parameter between 0.0 and 1.0. A value of 0.0 means
      always exploit (select best known action), while 1.0 means always explore (random
      selection). Typical values range from 0.1 to 0.3 for balanced learning.
  returns: Returns a uint32_t representing the index of the selected action. The value
    corresponds to an action in the AI's action set, where valid indices are typically
    between 0 and (number_of_actions - 1).
  examples:
  - title: Basic Q-learning action selection
    code: 'uint32_t action = qFunction.SelectAction(currentState, 0.1f);

      // Uses 10% exploration rate to balance between exploitation and exploration'
    language: cpp
  - title: Dynamic epsilon decay for learning
    code: 'float epsilon = std::max(0.01f, initialEpsilon - (episodeCount * decayRate));

      uint32_t action = qFunction.SelectAction(currentState, epsilon);

      // Gradually reduce exploration as learning progresses'
    language: cpp
  notes: This method assumes that the Q-function has been properly initialized with
    a valid Q-table and that the state and action spaces are correctly defined. The
    implementation likely uses a random number generator to determine whether to explore
    or exploit based on the epsilon value.
  warnings: Ensure that the state parameter corresponds to a valid index in your Q-table,
    otherwise behavior is undefined. Also, be cautious with very low epsilon values
    as they may cause the AI to get stuck in local optima if not properly initialized.
  related:
  - QFunction::UpdateQValue
  - QFunction::GetBestAction
  - QFunction::Initialize
metadata:
  confidence: 0.85
  generated_at: '2025-11-06T05:20:42.382036'
  generator: lmstudio-qwen3-coder-30b
  version: 1.0.0
  source: core
